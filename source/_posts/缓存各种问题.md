---
title: 缓存各种问题
date: 2020/11/07 17:03:01
toc: true
tags:
- redis
---

[缓存穿透](#缓存穿透)  
[缓存击穿](#缓存击穿)  
[缓存雪崩](#缓存雪崩)  
[缓存降级](#缓存降级)  
[缓存预热](#缓存预热)
<!--more-->

#### 缓存穿透
* 缓存穿透是指用户请求的数据在**缓存中不存在即没有命中，同时在数据库中也不存在**，导致用户每次请求该数据都要去数据库中查询一遍，然后返回空
* 有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据库上，造成数据库压力过大，甚至击垮数据库系统

解决方案
* 布隆过滤器
  * 布隆过滤器认为不在的，一定不会在集合中；布隆过滤器认为在的，可能在也可能不在集合中。
    * 爬虫系统url去重；垃圾邮件过滤；黑名单
    * 节省空间：不需要存储数据本身
    * 时间复杂度低：插入和查找的时间复杂度都为O(k)，k为哈希函数的个数
    * 存在假阳性：布隆过滤器判断存在，可能出现元素不在集合中；判断准确率取决于哈希函数的个数

* 返回空对象
  * 当缓存未命中，查询持久层也为空，可以将返回的**空对象写到缓存中**，这样下次请求该key时直接从缓存中查询返回空对象，请求不会落到持久层数据库。为了避免存储过多空对象，通常会给空对象设置一个**过期时间**。
  * 问题
    * 有大量的key穿透，缓存空对象会占用宝贵的内存空间
    * 空对象的key设置了过期时间，在这段时间可能会存在缓存和持久层数据不一致的场景

#### 缓存击穿
* 一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。
* 数据库瞬时压力骤增，造成大量请求阻塞

解决方案
* 互斥锁 mutex key
  * 一个线程回写缓存，其他线程等待回写缓存线程执行完，重新读缓存即可。
  * 同一时间只有一个线程读数据库然后回写缓存，其他线程都处于阻塞状态。如果是高并发场景，大量线程阻塞势必会降低吞吐量
  * 分布式应用就需要使用分布式锁
* 热点数据永不过期
  * 物理不过期，针对热点key不设置过期时间
  * 逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建
  * 对性能友好，对不追求强一致性的系统可以接受

#### 缓存雪崩
* 缓存中数据大批量到过期时间，而查询数据量巨大，请求直接落到数据库上，引起数据库压力过大甚至宕机
* 缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库

解决方案
* 均匀过期
  * 设置不同的过期时间，让缓存失效的时间点尽量均匀。通常可以为有效期增加随机值或者统一规划有效期。
* 加互斥锁
  * 同一时间只让一个线程构建缓存，其他线程阻塞排队。
  * 针对要求强一致性的系统
* 缓存永不过期
  * 缓存击穿解决思路一致，缓存在物理上永远不过期，用一个异步的线程更新缓存
* 双层缓存策略
  * 主缓存：有效期按照经验值设置，设置为主读取的缓存，主缓存失效后从数据库加载最新值。
  * 备份缓存：有效期长，获取锁失败时读取的缓存，主缓存更新时需要同步更新备份缓存。

#### 缓存预热
系统上线后，将相关的缓存数据直接加载到缓存系统，这样就可以避免在用户请求的时候，先查询数据库，然后再将数据回写到缓存

* 数据量不大的时候，工程启动的时候进行加载缓存动作；
* 数据量大的时候，设置一个定时任务脚本，进行缓存的刷新
* 数据量太大的时候，优先保证热点数据进行提前加载到缓存

#### 缓存降级
缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据

将部分热点数据缓存到服务的内存中，这样一旦缓存出现异常，可以直接使用服务的内存数据，从而避免数据库遭受巨大压力