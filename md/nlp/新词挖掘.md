[TOC]





![image-20190427103424869](/Users/K/Library/Application Support/typora-user-images/image-20190427103424869.png)



#### 新词的提取

* 利用词频选取候选词语，即种子词语
* 判别候选词语的**内部结合紧密程度**和**外部边界独立性**

##### seed word 挖掘

利用N-Gram对语料进行切分，得到词语片段，统计词语片段出现的频数。设定一个阈值，只有当词语片段出现的频数超过这个阈值时，才认为这个词语片段构成一个候选词语

##### 内部紧密度和外部边界独立性

由于仅通过词频筛选得到的词仍然具有较大的噪音，因此仍需要其他指标来进一步筛选

* 内部紧密程度

  从统计学的视角来看，词语内部的**结合紧密程度依赖于词语的共现频次**。如果某些相互成搭配的词语片段反复大量出现，即它们的共现频次越高，那么词语片段的结合紧密程度越强。但在实际应用中会发现，**词语片段共现频次高可能不是一个词**，而是多个词构成的词组。

  比如，在人人网用户状态语料中，“的电影”出现了389次，而“电影院”只出现了175次，然而我们却更倾向于把“电影院”当作一个词语。为了证明这种倾向，需要分别计算“的电影”和“电影院”两个词语片段的内部结合紧密程度，并比较它们的大小。
  * 内部紧密程度的衡量利用"互信息"。所谓互信息，指的就是两个事件同时发生的概率，体现两个变量的依赖程度 (pointwise mutual information)

    $\mathrm{I}(\mathrm{x} ; \mathrm{y})=\log \frac{p(x, y)}{p(x) p(y)}=\log \frac{p(x | y)}{p(x)}=\log \frac{p(y | x)}{p(y)}$

  * p(电影) = 2274 / (2400*100000) = 0.0000113,

    p(院) = 0.000001969, p(电影院) = 7.183 * $10^{-6}$

    MI(电影院) = $log \frac{p(电影院)}{p(电影)p(院)}$ = 323

* 外部边界独立性

  确保新词具有合法的语义，必须保证新词是独立的语言单位。 利用左右熵。

  左熵:

  $E_{L}(W)=-\sum_{\forall a \in A} P(a W | W) * \log _{2} P(a W | W)$

  右熵

  $E_{R}(W)=-\sum_{\forall b \in B} P(W b | W) * \log _{2} P(W b | W)$

  其中，W表示N-Gram切分后经过筛选的候选词语，$\mathrm{W}=\left\{w_{1}, w_{2}, w_{3}, \ldots, w_{n}\right\}$ ；A表示候选词语左边出现的所有词语的集合，a表示左边出现的某一个词语；B表示候选词语右边出现的所有词语的集合，b表示右边出现的某一个词语。

![image-20190427105439144](/Users/K/Library/Application Support/typora-user-images/image-20190427105439144.png)



#### 分词的目的

假设用朴素贝叶斯来解决分类问题，一个重要的前提假设就是特征之间的相互独立性。对于文本数据来说，如果以字作为最小单元，那么假设显然不成立，如"她喜欢唱歌" “喜”和“欢”之间有着相关性。 但是如果分完词后，那么“喜欢” 和 “唱歌”之间的相关性就没有那么强烈了。

**分词的主要目的之一，就是将句子分为若干个相关性比较弱的部分，便于进一步处理**

