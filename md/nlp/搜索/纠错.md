[TOC]



### 错误生成

#### 误操作

* 拼音输入法-- 同音异形字 周接论
* 笔画输入或手写出入 出现形似字 博和傅

#### 用户主观理解问题

飞扬拔（跋）扈

#### 用户图方便

直接输入拼音或者拼音前缀  或者就是因为记忆的原因，输错了



- 谐音。深圳-森圳。
- 别字。师傅-师博。
- 中英文。Taylor swift-泰勒斯威夫特。
- 近义词。爱情呼叫转移-恋爱呼叫转移。
- 形近字。高粱-高梁。
- 全拼。深圳-shenzhen。
- 拼音前缀。北京-bj。
- 内容不完整。唐人街探案-唐人



### 解决方法

#### 词典

高速、高准，如果词典的覆盖度高，甚至可以达到高召回的效果

对query找对应词典里有没有，如果有就改写过去

##### 词典的挖掘

底层数据库抽取，用户日志

##### 词典的类型

* 拼音和拼音前缀词典。先将query或者单词转为拼音，然后通过通过拼音召回对应的结果，完成纠错。

* 别字词典，记录一些常见的错别字，例如百度的形近词表就很不错（就在百度百科里面
* 其他改写字典。一般基于具体业务来改写，例如用户输入唐人街探案，其实唐人街探案有3部，我们应该给那个，需要基于热度等方面去改写到具体最合适的一部。



原则： 改写的内容不能和原来差距太远，通过编辑距离控制

语义相似度之类的操作，编辑距离一定要约束，**用户强调的是直观感受**，**语义相近与否不是他们第一个关心**的，只有**当字相近的结果不好的时候**考虑语义相近才是用户的实际反映。



#### 模型方法

泛化能力好

- 错误诊断。即判断有没有错。
- 修正召回。召回可能的修改项。保证召回率
- 修正确认。判断最终需要的修改项。保证准确率。



其实这个思路最广泛的应用就是推荐系统，召回和排序分离

- kenlm统计语言工具。运用统计学方法进行语言建模从而检测和修正错误。
- rnn_attention。RNN加上attention还是一个非常有意思的方法。
- rnn_crf模型：说起来你们可能不信，这个思路来自阿里2016参赛中文语法纠错比赛的第一名的方法。
- seq2seq_attention模型：比RNN强一些，长文本效果不错，但是容易过拟合。
- transformer：线性优秀的序列表征模型，大家懂的。
- bert：中文微调，最妙的是mask可协助纠正错别字。
- conv_seq2seq模型：基于Facebook出品的fairseq，在NLPCC-2018的中文语法纠错比赛中，是唯一使用单模型并取得第三名的成绩。



##### kenlm

[link](https://kheafield.com/code/kenlm/)

```
# install
sudo apt-get install build-essential libboost-all-dev cmake zlib1g-dev libbz2-dev liblzma-dev
wget -O - https://kheafield.com/code/kenlm.tar.gz |tar xz
mkdir kenlm/build
cd kenlm/build
cmake ..
make -j2
```

py包

```
pip install https://github.com/kpu/kenlm/archive/master.zip
```



直接train得到的 xx.arpa 文件里是统计各个 n-gram 的Pro,word,backPro,

* train完的model可以用来给句子打分，判断流畅度

* 分词-用lm做分词
* 新词发现
* 智能纠错

