---
title: 进程线程协程
date: 2020/11/11 15:47:35
toc: true
tags:
- python
---

<!--more-->

进程地址空间
* 栈:用于维护函数调用的上下文(包括函数的参数,局部变量)
* 堆:用于容纳程序中动态分配的内存区域
* 程序代码
* 文件等共享资源


#### 线程共享
* 线程共享的资源
  * 堆,堆是在进程空间开辟出来的
  * 全局变量,静态变量，其存放位置和全局变量一样, 在堆中开辟
  * 文件等共享资源(文件描述符),使用这些共享资源的线程必须同步
  * 地址空间

* 线程独享
  * 栈:用于维护函数调用的上下文(包括函数的参数,局部变量)
  * 寄存器,PC(程序计数器)
  * 状态(线程ID,状态字)

#### 线程切换比进程切换快
* 相对进程上下文切换,线程上下文切换时**地址空间保持不变**(即不需要切换当前使用的页表)
* 进程里的内存地址都是虚拟的,每次内存操作都要涉及虚拟地址转换成实际物理地址,I/O较高,因此引入TLB缓存,存储虚拟地址到真实地址的数据结构

多线程切换,会发生上下文切换,对于进程,需要把状态保存在进程控制块(PCB)中,对于线程,则需要一个或多个线程控制块(TCB)来保存每个线程的状态。

#### 协程切换代价小于线程
* 协程切换是在用户态,主要是通过在程序中主动让出CPU资源; 而线程切换是在内核空间完成,需要先从用户态切换到内核,完成切换后,从内核态切回用户态
* 协程切换-只涉及基本CPU上下文切换
  * CPU上下文,就是一些寄存器保存了CPU运行任务所需信息，从哪里运行(指令指针寄存器),栈顶位置(堆栈指针寄存器),当前栈帧起始位置
  * 线程除了和协程相同基本的上下文,还有私有的栈和寄存器。

#### 协程
* 单线程的**异步编程**模型,省去线程切换开销的时间,不用考虑线程安全(加锁,死锁之类的问题)
* python里的generator, goroutine
* **非抢占式调度**(线程是抢占式调度,即当前线程可能被打断，被另一个线程抢占),只有当协程让出(yield)执行体的时候才被打断

#### 线程和协程
* 节省CPU,避免线程的频繁切换
* 节约内存,系统内存的制约导致无法开启更多线程实现高并发
* 稳定性,进程中任意一个线程出错,会导致其他线程也崩溃

#### 线程和进程区别
* 进程是**资源（包括内存、打开的文件等）分配**的单位，线程是 **CPU 调度**的单位
* 资源的共享
  * 进程间的资源相互独立，同一进程内的线程之间共享资源
* 初始化和销毁一个进程的成本比线程高
  * 进程创建撤销涉及系统分配回收资源如**内存空间，I/O设备**，切换涉及当前**执行进程CPU环境的保**存及新调度进程CPU环境的设置
  * 同一个进程内的线程切换比进程切换快，因为**线程具有相同的地址空间**（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页**表的切换过程开销是比较大的**





#### python 能多线程运行吗 为什么 怎么办
python的线程虽然是真正的线程，但是解释器执行代码时，有一个GIL锁 Global Interpreter Lock, 

* 任何python线程执行前，必须先获得GIL锁，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。 
* 全局锁相当于把所有的线程执行代码都上锁了，多线程在Python中只能交替执行
* 100个线程跑在100核CPU上，也只能用到1个核。
* 可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响


#### GIL的枷锁和释放锁的过程， 如何实现
* GIL导致同一时刻，同一进程只能有一个线程运行在cpu上。
* GIL加在Cpython解释器中，其他解释器中不会有GIL
* GIL: 一个线程拥有解释器的访问权后，其他所有线程必须等待它释放解释器的访问权，即使这些线程的下一条命令并不互相影响

#### 为什么有GIL锁
* Cpython**内存管理不是线程安全**的,需要GIL确保多个原生线程不会并发执行py字节码
* GIL真正影响的是Cpython字节码的执行，像IO，图形处理，numpy科学计算这些耗时操作都是**发生在GIL之外**的
* 用GIL而非管理锁的原因
  * 单线程更快
  * 瓶颈在IO的多线程环境更快
  * 不需要考虑线程安全问题
* Python 标准库会在每次 I/O **阻塞结束后释放 GIL**，因此 GIL 不会对 I/O 服务器产生很大的性能影响

#### 怎么实现进程间通信
* multiprocessing的Queue,支持put和get
  * 放入的对象必须是可以pickle的
  * Queue底层也是Pipe实现的,实际上进程并不是直接将对象写入到Pipe里面，而是先写入一个本地的buffer，再由一个专门的feed线程将其放入Pipe当中。
  * 在内存中开辟队列结构空间，多个进程可见.多个进程操作同一个队列对象可以实现消息存取工作
* Pipe
  * 在内存中开辟一块内存空间，形成管道结构, 多个进程使用同一个管道，即可通过对管道的读写操作进行通讯
  * `(parentConn, childConn) = Pipe()`
  * 管道有两端,一端send data,一端receive data,这种模式适合父子进程之间的通信
  * 管道的两端也可以实现同时发送接收消息
* Manager
  * 其支持的类型包括 list, dict, Namespace, Lock, RLock, Semaphore, BoundedSemaphore, Condition, Event, Queue, Value, Array
  * 相比于共用内存，Manager 可以让**不同机器上的进程**通过**网络共享**对象
  * Manager 的 register 方法还可以自定义新的类型或者可调用对象
  * Manager中的Queue的作用是用来传递任务和接收结果，每个任务的描述数据量要尽量小
* 共享内存通信
  *  在内存中开辟一段空间存储数据对多个进程可见，每次写入共享内存中的内容都会覆盖之前内容,对内存的读操作不会改变内存中的内容

#### 进程池
* 如果有**大量的任务需要多进程**完成，而**调用周期比较短**且需**要频繁创建**。此时可能产生大量进程频繁创建销毁的情况,消耗计算机资源较大
* map和apply的区别
  * map方法会将数组参数迭代传给被调用方法
  * apply只是调用方法和参数
* pool.map(func, range(10)) / pool.apply(func, (i, ))
* map和apply都有async即非阻塞的方式,即不会阻塞主进程, 需要用pool.close()和join()方法阻塞等待子进程执行

#### 同步与异步，阻塞与非阻塞
* 同步
  * 一个进程执行某个请求时,若请求需要一段时间才能返回信息，则该进程会一直等待下去，直到收到返回信息才继续执行
* 异步
  * 进程不需要一直等下去，而是继续执行下面的操作，当有消息返回时，系统通知进程进行处理





#### 信号量 Semaphore
多线程中同步对共享资源的使用，用于标明当前**共享资源可以有多少并发读取**。同时也可以**实现线程的同步**。
* 每当调用acquire()时，内置计数器-1
* 每当调用release()时，内置计数器+1
* 计数器不能小于0，当计数器为0时，acquire()将阻塞线程直到其他线程调用release()

应用:
* 主要用在数据库应用中，比如连接数据库的连接，**限制同时连接的数量**，如数据库连接池
* semaphore中的数量用于控制并发的数量
  * 例如爬网站,控制并发数为3.
  
  ``` py
  class htmlSpider(threading.Thread):
      def __init__(self, url, sem):
          super().__init__()
          self.url = url
          self.sem = sem

      def run(self):
          time.sleep(2)
          print("got html text success")
          self.sem.release() # 内部维护的计数器加1，并通知内部维护的conditon通知acquire

  class UrlProducer(threading.Thread):
      def __init__(self, sem):
          super().__init__()
          self.sem = sem

      def run(self):
          for i in range(20):
              self.sem.acquire() # 内部维护的计数器减1，到0就会阻塞
              html_thread = htmlSpider("http://baidu.com/{}".format(i), self.sem)
              html_thread.start()

  if __name__ == "__main__":
      sem = threading.Semaphore(3) #设置同时最多3个
      url_producer = UrlProducer(sem)
      url_producer.start()
  ``` 
* 线程的同步
  * semaphore = threading.Semaphore(0)
  * producer在semaphore.release()后, consumer才能semaphore.acquire()

#### 线程同步
* Lock实现,
* RLock 只有拿到锁的线程才能释放该锁
  * 可以避免死锁
  * 同一线程可以多次拿到该锁，即可以acquire多次
  * acquire多少次就必须release多少次，只有最后一次release才能改变RLock的状态为unlocked
* 利用锁排序
  * 死锁通常发生在线程同时获取多个锁造成的, 一个线程获取了第一个锁，然后在获取第二个锁的时候发生阻塞，那么这个线程就可能阻塞其他线程的执行，从而导致整个程序假死
  * 为程序中的每一个锁分配一个唯一的id，然后只允许按照升序规则来使用多个锁，这个规则使用上下文管理器 是非常容易实现的
* 信号量实现两个线程 生产者消费者
  * semaphore设为0，producer在生产东西后semaphore.release(), 然后customer这时候 semaphore.acquire()才能进去
  * 信号量为1可以实现互斥锁，
* 事件Event进行线程同步


#### 多线程Event
* 场景: 启动了多个线程，这些线程都要去**访问一个资源**，但是，即将被访问的资源还没有准备好接受访问，那么此时，多个线程去访问，必然得到不响应，你还得处理这种得不到响应的情况,
* 能否先在主线程里去做试探，确定资源可以访问以后，再让已经启动了的多线程
* 创建一个Event对象，现在，事件内部标识是False
* 启动多线程，线程里调用wait方法，这时，会阻塞
* 主线程去试探，确定资源可访问以后，调用set方法
* 已经调用wait的线程接手到事件信息，访问资源




#### 事件 Event



#### 进程通信


#### Condition
* threading库的condition的方法有
  * acquire() / release()
  * wait() / notify()
* Condition对象维护一个锁(lock/Rlock),以及一个waiting池
  * 线程通过acquire获得Condition对象
  * 调用wait时,线程释放Condition**内部锁**,并进入blocked状态,waiting池记录这个线程
  * 调用notify时,Condition对象会从waiting池挑选一个线程，通知其调用acquire方法