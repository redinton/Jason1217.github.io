[TOC]



#### 下面哪些技术跟中文分词有关

---

词语消歧；未登录词识别；词性标注

无关的: 关系识别; 句法分析; 意图识别; 槽位填充



#### 有助于解决深度网络的梯度消失

---

**预训练+微调**; 控制网络深度;使用残差结构; 使用LSTM; 采用Batch Normalization



####以下几种优化算法中，哪一种最快

---

**BFGS (拟牛顿法)**； 梯度下降法；牛顿法；Adam



####BN有哪些作用

---

1. 加速收敛
2. 控制过拟合，可以少用或不用Dropout和正则
   1. 使用BN训练时，一个样本只与minibatch中其他样本有相互关系；对于同一个训练样本，网络的输出会发生变化。这些效果有助于提升网络泛化能力，像dropout一样防止网络过拟合，同时BN的使用，可以减少或者去掉dropout类似的策略
3. 降低网络对初始化权重敏感
4. 允许使用较大的学习率



#### 关于Word2vec

---

Word2vec是无监督学习 ； Word2vec没有使用完全的深度神经网络模型



####决策树通过预剪枝和后剪枝提升模型的泛化能力。

---

结论是正确的

预剪枝使得很多分支没有展开，这不仅降低了过拟合的风险，还显著减少了决策树的训练时间开销和测试时间。因此预剪枝的这种贪心本质，给决策树带来了欠拟合的风险。

后剪枝通常比预剪枝保留更多的分支，其欠拟合风险很小，因此后剪枝的泛化性能往往由于预剪枝决策树。但后剪枝过程是从底往上裁剪，因此其训练时间开销比前剪枝要大。